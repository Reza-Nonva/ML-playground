{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Breast Cancer Classification using Perceptron, AdalineGD, and Logistic Regression\n",
    "\n",
    "This notebook explores the classification of breast cancer data using three different models: Perceptron, AdalineGD, and Logistic Regression. The goal is to train and evaluate these models to predict whether a tumor is malignant or benign based on the features in the dataset.\n",
    "\n",
    "## Steps Covered:\n",
    "1. Data Loading and Preprocessing\n",
    "2. Exploratory Data Analysis (EDA)\n",
    "3. Standardize the data to improve model performance.\n",
    "4. Implementation and Training of the Perceptron Model.\n",
    "5. Implementation and Training of the AdalineGD Model.\n",
    "6. Training Logistic Regression Model\n",
    "\n",
    "Dataset: [Breast Cancer Data Set](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "49713bfd12dddb0b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1. import Breast cancer Dataset from sklearn"
   ],
   "metadata": {
    "id": "293a6803-1da7-4f3d-aaac-7633afe96916"
   },
   "id": "293a6803-1da7-4f3d-aaac-7633afe96916"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = load_breast_cancer()\n",
    "\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Split the data into training and testing sets (80% for training and 20% for testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size =0.2, random_state=45)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "855bed7eb7dcefbf",
    "outputId": "87c91a7a-13fa-4ea0-bf4d-e999d66a01b7",
    "ExecuteTime": {
     "end_time": "2024-10-12T11:45:52.573042754Z",
     "start_time": "2024-10-12T11:45:48.970226168Z"
    }
   },
   "id": "855bed7eb7dcefbf",
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. Exploratory Data Analysis (EDA)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3b9e18956323bb1c"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
      "0        11.76         21.60           74.72      427.9          0.08637   \n",
      "1        11.54         10.72           73.73      409.1          0.08597   \n",
      "2        11.60         24.49           74.23      417.2          0.07474   \n",
      "3        19.81         22.15          130.00     1260.0          0.09831   \n",
      "4        13.00         21.82           87.50      519.8          0.12730   \n",
      "\n",
      "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
      "0           0.04966         0.01657             0.011150         0.1495   \n",
      "1           0.05969         0.01367             0.008907         0.1833   \n",
      "2           0.05688         0.01974             0.013130         0.1935   \n",
      "3           0.10270         0.14790             0.094980         0.1582   \n",
      "4           0.19320         0.18590             0.093530         0.2350   \n",
      "\n",
      "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
      "0                 0.05888  ...          25.72            82.98       516.5   \n",
      "1                 0.06100  ...          12.87            81.23       467.8   \n",
      "2                 0.05878  ...          31.62            81.39       476.5   \n",
      "3                 0.05395  ...          30.88           186.80      2398.0   \n",
      "4                 0.07389  ...          30.73           106.20       739.3   \n",
      "\n",
      "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
      "0           0.10850            0.08615          0.05523               0.03715   \n",
      "1           0.10920            0.16260          0.08324               0.04715   \n",
      "2           0.09545            0.13610          0.07239               0.04815   \n",
      "3           0.15120            0.31500          0.53720               0.23880   \n",
      "4           0.17030            0.54010          0.53900               0.20600   \n",
      "\n",
      "   worst symmetry  worst fractal dimension  target  \n",
      "0          0.2433                  0.06563       1  \n",
      "1          0.3390                  0.07434       1  \n",
      "2          0.3244                  0.06745       1  \n",
      "3          0.2768                  0.07615       0  \n",
      "4          0.4378                  0.10720       0  \n",
      "\n",
      "[5 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(X_train, columns=data.feature_names)\n",
    "df['target'] = y_train\n",
    "\n",
    "print(df.head())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-12T11:45:52.655511353Z",
     "start_time": "2024-10-12T11:45:52.606374763Z"
    }
   },
   "id": "31452281fbb69afb",
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3. Standardize the features"
   ],
   "metadata": {
    "collapsed": false,
    "id": "76d29848b151372f"
   },
   "id": "76d29848b151372f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std= sc.transform(X_test)"
   ],
   "metadata": {
    "id": "ec3e04c5998183e5",
    "ExecuteTime": {
     "end_time": "2024-10-12T11:45:52.743032900Z",
     "start_time": "2024-10-12T11:45:52.657010172Z"
    }
   },
   "id": "ec3e04c5998183e5",
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4-1. Implementation of the Perceptron Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "24ae209e5e3e6e5f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class Perceptron:\n",
    "    \"\"\"Perceptron classifier.\n",
    "\n",
    "    Parameters\n",
    "    ------------\n",
    "    eta : float\n",
    "      Learning rate (between 0.0 and 1.0)\n",
    "    n_iter : int\n",
    "      Passes over the training dataset.\n",
    "    random_state : int\n",
    "      Random number generator seed for random weight\n",
    "      initialization.\n",
    "\n",
    "    Attributes\n",
    "    -----------\n",
    "    w_ : 1d-array\n",
    "      Weights after fitting.\n",
    "    b_ : Scalar\n",
    "      Bias unit after fitting.\n",
    "    errors_ : list\n",
    "      Number of misclassifications (updates) in each epoch.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, eta=0.01, n_iter=50, random_state=1):\n",
    "        self.eta = eta\n",
    "        self.n_iter = n_iter\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fit training data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like}, shape = [n_examples, n_features]\n",
    "          Training vectors, where n_examples is the number of examples and\n",
    "          n_features is the number of features.\n",
    "        y : array-like, shape = [n_examples]\n",
    "          Target values.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "\n",
    "        \"\"\"\n",
    "        rgen = np.random.RandomState(self.random_state)\n",
    "        self.w_ = rgen.normal(loc=0.0, scale=0.01, size=X.shape[1])\n",
    "        self.b_ = np.float64(0.)\n",
    "\n",
    "        self.errors_ = []\n",
    "\n",
    "        for _ in range(self.n_iter):\n",
    "            errors = 0\n",
    "            for xi, target in zip(X, y):\n",
    "                update = self.eta * (target - self.predict(xi))\n",
    "                self.w_ += update * xi\n",
    "                self.b_ += update\n",
    "                errors += int(update != 0.0)\n",
    "            self.errors_.append(errors)\n",
    "        return self\n",
    "\n",
    "    def net_input(self, X):\n",
    "        \"\"\"Calculate net input\"\"\"\n",
    "        return np.dot(X, self.w_) + self.b_\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Return class label after unit step\"\"\"\n",
    "        return np.where(self.net_input(X) >= 0.0, 1, 0)"
   ],
   "metadata": {
    "id": "ea4e405c-68fd-48d5-a655-b03ec9d1fa60",
    "ExecuteTime": {
     "end_time": "2024-10-12T11:45:52.816789190Z",
     "start_time": "2024-10-12T11:45:52.697994826Z"
    }
   },
   "id": "ea4e405c-68fd-48d5-a655-b03ec9d1fa60",
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4-2. Train the Perceptron model and calculate its accuracy"
   ],
   "metadata": {
    "collapsed": false,
    "id": "467621710659f8dc"
   },
   "id": "467621710659f8dc"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron Accuracy: 0.982\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "eta = 0.01 #learning rate\n",
    "epochs = 16 #number of epochs\n",
    "ppn = Perceptron(eta=eta, n_iter=epochs)\n",
    "ppn.fit(X_train_std, y_train)\n",
    "\n",
    "# calculate accuracy\n",
    "ppn_y_pred = ppn.predict(X_test_std)\n",
    "ppn_accu = accuracy_score(y_test, ppn_y_pred)\n",
    "print('Perceptron Accuracy: %.3f' % ppn_accu)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6a4e5e166aab85fd",
    "outputId": "ae8c72ec-90ad-4f22-e4ce-cd5545239f12",
    "ExecuteTime": {
     "end_time": "2024-10-12T11:45:53.477108243Z",
     "start_time": "2024-10-12T11:45:52.825948788Z"
    }
   },
   "id": "6a4e5e166aab85fd",
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5-1. Implementation of the AdalineGD model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "52849ec2f1ad7f4b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class AdalineGD:\n",
    "    \"\"\"ADAptive LInear NEuron classifier.\n",
    "\n",
    "    Parameters\n",
    "    ------------\n",
    "    eta : float\n",
    "      Learning rate (between 0.0 and 1.0)\n",
    "    n_iter : int\n",
    "      Passes over the training dataset.\n",
    "    random_state : int\n",
    "      Random number generator seed for random weight\n",
    "      initialization.\n",
    "\n",
    "\n",
    "    Attributes\n",
    "    -----------\n",
    "    w_ : 1d-array\n",
    "      Weights after fitting.\n",
    "    b_ : Scalar\n",
    "      Bias unit after fitting.\n",
    "    losses_ : list\n",
    "      Mean squared eror loss function values in each epoch.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, eta=0.01, n_iter=50, random_state=1):\n",
    "        self.eta = eta\n",
    "        self.n_iter = n_iter\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\" Fit training data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like}, shape = [n_examples, n_features]\n",
    "          Training vectors, where n_examples is the number of examples and\n",
    "          n_features is the number of features.\n",
    "        y : array-like, shape = [n_examples]\n",
    "          Target values.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "\n",
    "        \"\"\"\n",
    "        rgen = np.random.RandomState(self.random_state)\n",
    "        self.w_ = rgen.normal(loc=0.0, scale=0.01, size=X.shape[1])\n",
    "        self.b_ = np.float64(0.)\n",
    "        self.losses_ = []\n",
    "\n",
    "        for i in range(self.n_iter):\n",
    "            net_input = self.net_input(X)\n",
    "            # Please note that the \"activation\" method has no effect\n",
    "            # in the code since it is simply an identity function. We\n",
    "            # could write `output = self.net_input(X)` directly instead.\n",
    "            # The purpose of the activation is more conceptual, i.e.,  \n",
    "            # in the case of logistic regression (as we will see later), \n",
    "            # we could change it to\n",
    "            # a sigmoid function to implement a logistic regression classifier.\n",
    "            output = self.activation(net_input)\n",
    "            errors = (y - output)\n",
    "            \n",
    "            #for w_j in range(self.w_.shape[0]):\n",
    "            #    self.w_[w_j] += self.eta * (2.0 * (X[:, w_j]*errors)).mean()\n",
    "            \n",
    "            self.w_ += self.eta * 2.0 * X.T.dot(errors) / X.shape[0]\n",
    "            self.b_ += self.eta * 2.0 * errors.mean()\n",
    "            loss = (errors**2).mean()\n",
    "            self.losses_.append(loss)\n",
    "        return self\n",
    "\n",
    "    def net_input(self, X):\n",
    "        \"\"\"Calculate net input\"\"\"\n",
    "        return np.dot(X, self.w_) + self.b_\n",
    "\n",
    "    def activation(self, X):\n",
    "        \"\"\"Compute linear activation\"\"\"\n",
    "        return X\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Return class label after unit step\"\"\"\n",
    "        return np.where(self.activation(self.net_input(X)) >= 0.5, 1, 0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-12T11:45:53.856771889Z",
     "start_time": "2024-10-12T11:45:53.479175451Z"
    }
   },
   "id": "dabef615e8624ba4",
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5-2. Train the AdalineGD model and calculate its accuracy"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "371ba4425bba609e"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdalineGD Accuracy: 0.965\n"
     ]
    }
   ],
   "source": [
    "adaline = AdalineGD(eta=0.01, n_iter=100)\n",
    "adaline.fit(X_train_std, y_train)\n",
    "\n",
    "# calculate accuracy\n",
    "adaline_y_pred = adaline.predict(X_test_std)\n",
    "adaline_accu = accuracy_score(y_test, adaline_y_pred)\n",
    "print('AdalineGD Accuracy: %.3f' % adaline_accu)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-12T11:45:54.159857076Z",
     "start_time": "2024-10-12T11:45:53.862475093Z"
    }
   },
   "id": "c28cfa80110406f",
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 6. Import Logistic Regression"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ad310fbef59928c5"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-12T11:45:55.292200184Z",
     "start_time": "2024-10-12T11:45:54.158608457Z"
    }
   },
   "id": "11e02d67c0f79ac0",
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train the Logistic Regression model and calculate its accuracy"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5d60d67f194537ce"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.982\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(C=1.0, solver='lbfgs', max_iter=100)\n",
    "\n",
    "lr.fit(X_train_std, y_train)\n",
    "\n",
    "lr_y_pred = lr.predict(X_test_std)\n",
    "\n",
    "lr_accu = accuracy_score(y_test,  lr_y_pred)\n",
    "print('Logistic Regression Accuracy: %.3f' %lr_accu) "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-12T11:45:55.334095649Z",
     "start_time": "2024-10-12T11:45:55.303116843Z"
    }
   },
   "id": "288533c69720c164",
   "execution_count": 9
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
